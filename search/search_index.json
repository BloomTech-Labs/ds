{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Labs!","title":"Home"},{"location":"bigdata/","text":"Big Data What if your data doesn\u2019t fit in memory? My advice: Try to \u201cscale up\u201d (use a server with more memory) before you try to \u201cscale out\u201d (use distributed computing frameworks). If you\u2019re looking at frameworks, try something lightweight like Dask before something heavy-duty like Spark. If you\u2019re fitting models, figure out whether more data is actually useful: Read \"More data or better models?\" by Xavier Amatriain, based on his experience leading ML Engineering at Netflix. Read about Learning curves in Scikit-Learn in Python Data Science Handbook by Jake VanderPlas. Then, decide whether to use a smaller sample that does fit in memory, or, try \u201cincremental learning\u201d in scikit-learn or Dask .","title":"Big Data"},{"location":"bigdata/#big-data","text":"What if your data doesn\u2019t fit in memory? My advice: Try to \u201cscale up\u201d (use a server with more memory) before you try to \u201cscale out\u201d (use distributed computing frameworks). If you\u2019re looking at frameworks, try something lightweight like Dask before something heavy-duty like Spark. If you\u2019re fitting models, figure out whether more data is actually useful: Read \"More data or better models?\" by Xavier Amatriain, based on his experience leading ML Engineering at Netflix. Read about Learning curves in Scikit-Learn in Python Data Science Handbook by Jake VanderPlas. Then, decide whether to use a smaller sample that does fit in memory, or, try \u201cincremental learning\u201d in scikit-learn or Dask .","title":"Big Data"},{"location":"deployment/","text":"Deployment Architecture You will design and document your architecture to deploy your model and integrate it into your product. For example: Labs 17 Cryptolytic architecture (diagram made with Lucidchart ) Labs 19 Tally AI architecture (diagram made with Figma ) FastAPI FastAPI is an alternative to Flask. It gives you \"automatic interactive API documentation.\" repo docs screencasts Porting Flask to FastAPI for ML Model Serving Resources Lambda students Elizabeth Ter Sahakyan, Create An API To Deploy Machine Learning Models Using Flask and Heroku Marvin Davila, Deploying a Flask App to AWS Elastic Beanstalk Marvin Davila, How to Create an AWS Lambda Function in Cloud9 Marvin Davila, How to Rate Limit Routes in Flask Quinn Dougherty, Build Week Survival Guide: Data Engineering Third party Soledad Galli, Deployment of Machine Learning Models (Udemy course, 8 hours of videos, $12)","title":"Deployment"},{"location":"deployment/#deployment","text":"","title":"Deployment"},{"location":"deployment/#architecture","text":"You will design and document your architecture to deploy your model and integrate it into your product. For example: Labs 17 Cryptolytic architecture (diagram made with Lucidchart ) Labs 19 Tally AI architecture (diagram made with Figma )","title":"Architecture"},{"location":"deployment/#fastapi","text":"FastAPI is an alternative to Flask. It gives you \"automatic interactive API documentation.\" repo docs screencasts Porting Flask to FastAPI for ML Model Serving","title":"FastAPI"},{"location":"deployment/#resources","text":"","title":"Resources"},{"location":"deployment/#lambda-students","text":"Elizabeth Ter Sahakyan, Create An API To Deploy Machine Learning Models Using Flask and Heroku Marvin Davila, Deploying a Flask App to AWS Elastic Beanstalk Marvin Davila, How to Create an AWS Lambda Function in Cloud9 Marvin Davila, How to Rate Limit Routes in Flask Quinn Dougherty, Build Week Survival Guide: Data Engineering","title":"Lambda students"},{"location":"deployment/#third-party","text":"Soledad Galli, Deployment of Machine Learning Models (Udemy course, 8 hours of videos, $12)","title":"Third party"},{"location":"examples/","text":"Examples Labs 20 Labs 20\u2019s top 2 products were DS cross-functional. See for yourself! Trash Panda: app , notion , repo , video Sound Drip: app , notion , repo , video Labs 12 Labs 12 was the first cohort with DS! Larkist video","title":"Examples"},{"location":"examples/#examples","text":"","title":"Examples"},{"location":"examples/#labs-20","text":"Labs 20\u2019s top 2 products were DS cross-functional. See for yourself! Trash Panda: app , notion , repo , video Sound Drip: app , notion , repo , video","title":"Labs 20"},{"location":"examples/#labs-12","text":"Labs 12 was the first cohort with DS! Larkist video","title":"Labs 12"},{"location":"expectations/","text":"Expectations Contribute daily Success starts with showing up. Are you showing up to participate with your team, on Slack, Zoom, and GitHub? Do you have something to show for your work, some tangible artifact, each day? This doesn't have to be just production code. For example, documentation is valuable, such as a data dictionary, with definitions, assumptions, and metadata. Jupyter notebooks with exploratory analysis are helpful to learn about the data and refine project plans. Regardless of the work format, it should be committed to GitHub or Notion. To help teams review and troubleshoot their work, we need to be able to see it in central repositories. Machine Learning will be < 20% of your time See Monica Rogati's diagram from her blog post, The AI Hierarchy of Needs :","title":"Expectations"},{"location":"expectations/#expectations","text":"","title":"Expectations"},{"location":"expectations/#contribute-daily","text":"Success starts with showing up. Are you showing up to participate with your team, on Slack, Zoom, and GitHub? Do you have something to show for your work, some tangible artifact, each day? This doesn't have to be just production code. For example, documentation is valuable, such as a data dictionary, with definitions, assumptions, and metadata. Jupyter notebooks with exploratory analysis are helpful to learn about the data and refine project plans. Regardless of the work format, it should be committed to GitHub or Notion. To help teams review and troubleshoot their work, we need to be able to see it in central repositories.","title":"Contribute daily"},{"location":"expectations/#machine-learning-will-be-20-of-your-time","text":"See Monica Rogati's diagram from her blog post, The AI Hierarchy of Needs :","title":"Machine Learning will be &lt; 20% of your time"},{"location":"planning/","text":"Planning Plans can be flexible and iterative. We don't expect DS students to stick to your original plan \u2014 but we do expect you to make one. President Eisenhower is famously quoted: \"In preparing for battle I have always found that plans are useless, but planning is indispensable.\" This is true of DS too! Translate user problems into DS problems DS students should participate in creating low-fidelity mockups, to get shared understanding, and make products that make a difference. This is recommended in Stakeholder-Driven Data Science at Warby Parker: First and foremost, we start with mockups to verify that if we put this deliverable in front of a decision maker, could they actually do something different. We then spend some time thinking about the business value for a project. We then do rapid iteration, using fake data or using messy data. Just to say, \u201cHey, can we align on exactly what this thing is going to look like before we go and do all the hard work of all the data cleaning? Just saying, \u201cHere\u2019s a couple of outputs that some different kinds of models could tell you. Which of these outputs is most useful to you?\u201d Finally, then we do the part that\u2019s actually data science in the traditional sense. I have found that becoming passionate about delivering data science products back to stakeholders can be just as satisfying as getting the correct math. If we do that, we\u2019re going to wind up in a place where data science is a really respected, mature discipline that gets the attention and budget it deserves. What data is available? Building Machine Learning Powered Applications lists these \"levels of data availability, from best-case scenario to most challenging\": Labeled data exists. Weakly labeled data exists. \"Some datasets contain labels that are not exactly a modeling target, but somewhat correlated with it. Playback and skip history for a music streaming service are examples of a weakly labeled dataset for predicting whether a user dislikes a song.\" Unlabeled data exists. \"This means we need to label the dataset, find a model that can learn from unlabeled data, or do a little bit of both.\" We need to acquire data. What level of data is available for your product? How will you measure success? As part of the planning process, teams must decide, how will we measure success on our problem? For example, a recommender system could be evaluated with a variety of metrics, including: Precision, the % of products recommended that you like. Minimizes false positives. Recall, the % of products you'd like that are recommended. Minimizes false negatives. Whenever possible, align metrics to the decision-making context and optimize for impact, such as increased sales from your recommender system. Dollars are a great metric. Then, using the metric you chose, begin with baselines. What's the simplest heuristic you can use? For example, what if you just always recommended the most popular product to everyone? What would your evaluation metrics look like then? Can you make a model to beat this baseline? Plot your progress Track your team's progress like how the EFF tracks AI research progress \u2014 with time on the x-axis, an evaluation metric on the y-axis, and a datapoint for each attempt, compared to some baseline: We care less about the end result (how high the metric goes at the end of the project) and more about the effort rate (how many attempts are made to iterate early). Your line's slope measures your learning rate. Choose your next step The team's project plan doesn't need to be detailed, but individual next steps do. At any given time, all DS students should have identified a concrete, detailed, tactical, specific next step. Labs Managers don't want to micromanage or disrupt flow. We just want to know, do you know what to do next, and how to do it? Or are you stuck? Knowing what to do next can be harder than the \"how.\" Students have learned the skills they need during core instruction, but Labs is the first time that most students put all the pieces together in a multi-week, cross-functional, team project. So, you can use checklists and flowcharts, like this data analysis checklist and visualization checklist , to help you be productive and deliver quality work. Resources Emmanuel Ameisen, Building Machine Learning Powered Applications: Going from Idea to Product, Preface & Chapter 1 , free 40 page PDF Max Shron, Stakeholder-Driven Data Science at Warby Parker , 30 minute video with transcript Jacqueline Nolis, You're Not Paid to Model , 25 minute video","title":"Planning"},{"location":"planning/#planning","text":"Plans can be flexible and iterative. We don't expect DS students to stick to your original plan \u2014 but we do expect you to make one. President Eisenhower is famously quoted: \"In preparing for battle I have always found that plans are useless, but planning is indispensable.\" This is true of DS too!","title":"Planning"},{"location":"planning/#translate-user-problems-into-ds-problems","text":"DS students should participate in creating low-fidelity mockups, to get shared understanding, and make products that make a difference. This is recommended in Stakeholder-Driven Data Science at Warby Parker: First and foremost, we start with mockups to verify that if we put this deliverable in front of a decision maker, could they actually do something different. We then spend some time thinking about the business value for a project. We then do rapid iteration, using fake data or using messy data. Just to say, \u201cHey, can we align on exactly what this thing is going to look like before we go and do all the hard work of all the data cleaning? Just saying, \u201cHere\u2019s a couple of outputs that some different kinds of models could tell you. Which of these outputs is most useful to you?\u201d Finally, then we do the part that\u2019s actually data science in the traditional sense. I have found that becoming passionate about delivering data science products back to stakeholders can be just as satisfying as getting the correct math. If we do that, we\u2019re going to wind up in a place where data science is a really respected, mature discipline that gets the attention and budget it deserves.","title":"Translate user problems into DS problems"},{"location":"planning/#what-data-is-available","text":"Building Machine Learning Powered Applications lists these \"levels of data availability, from best-case scenario to most challenging\": Labeled data exists. Weakly labeled data exists. \"Some datasets contain labels that are not exactly a modeling target, but somewhat correlated with it. Playback and skip history for a music streaming service are examples of a weakly labeled dataset for predicting whether a user dislikes a song.\" Unlabeled data exists. \"This means we need to label the dataset, find a model that can learn from unlabeled data, or do a little bit of both.\" We need to acquire data. What level of data is available for your product?","title":"What data is available?"},{"location":"planning/#how-will-you-measure-success","text":"As part of the planning process, teams must decide, how will we measure success on our problem? For example, a recommender system could be evaluated with a variety of metrics, including: Precision, the % of products recommended that you like. Minimizes false positives. Recall, the % of products you'd like that are recommended. Minimizes false negatives. Whenever possible, align metrics to the decision-making context and optimize for impact, such as increased sales from your recommender system. Dollars are a great metric. Then, using the metric you chose, begin with baselines. What's the simplest heuristic you can use? For example, what if you just always recommended the most popular product to everyone? What would your evaluation metrics look like then? Can you make a model to beat this baseline?","title":"How will you measure success?"},{"location":"planning/#plot-your-progress","text":"Track your team's progress like how the EFF tracks AI research progress \u2014 with time on the x-axis, an evaluation metric on the y-axis, and a datapoint for each attempt, compared to some baseline: We care less about the end result (how high the metric goes at the end of the project) and more about the effort rate (how many attempts are made to iterate early). Your line's slope measures your learning rate.","title":"Plot your progress"},{"location":"planning/#choose-your-next-step","text":"The team's project plan doesn't need to be detailed, but individual next steps do. At any given time, all DS students should have identified a concrete, detailed, tactical, specific next step. Labs Managers don't want to micromanage or disrupt flow. We just want to know, do you know what to do next, and how to do it? Or are you stuck? Knowing what to do next can be harder than the \"how.\" Students have learned the skills they need during core instruction, but Labs is the first time that most students put all the pieces together in a multi-week, cross-functional, team project. So, you can use checklists and flowcharts, like this data analysis checklist and visualization checklist , to help you be productive and deliver quality work.","title":"Choose your next step"},{"location":"planning/#resources","text":"Emmanuel Ameisen, Building Machine Learning Powered Applications: Going from Idea to Product, Preface & Chapter 1 , free 40 page PDF Max Shron, Stakeholder-Driven Data Science at Warby Parker , 30 minute video with transcript Jacqueline Nolis, You're Not Paid to Model , 25 minute video","title":"Resources"}]}